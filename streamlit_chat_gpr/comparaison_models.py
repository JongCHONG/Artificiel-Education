import requests
import time
import os
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer, util
import numpy as np

load_dotenv()

# Cl√© Api et Url
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
API_URL = os.getenv("GROQ_API_URL")

# Mod√®les √† comparer
MODELS = {
    "llama3" : "llama3-70b-8192",
    "gemma2" : "gemma2-9b-it",
    "mixtral" : "mixtral-8x7b-32768"
}

# Questions d'√©valuation
QUESTIONS = [
    "Peux-tu expliquer simplement le th√©or√®me de Pythagore ?",
    "Quelle est la diff√©rence entre ADN et ARN ?",
    "Comment r√©soudre une √©quation du second degr√© ?",
    "Qu'est-ce que la photosynth√®se ?",
    "Explique-moi la seconde guerre mondiale ?"
]

REFERENCES = [
    "Le th√©or√®me de Pythagore affirme que dans un triangle rectangle, le carr√© de l'hypot√©nuse est √©gal √† la somme des carr√©s des deux autres c√¥t√©s.",
    "L'ADN est le support de l'information g√©n√©tique dans les cellules, tandis que l'ARN sert principalement √† transmettre cette information et √† aider √† la synth√®se des prot√©ines.",
    "Pour r√©soudre une √©quation du second degr√©, on utilise la formule quadratique : x = (-b ¬± ‚àö(b¬≤ - 4ac)) / (2a), o√π a, b et c sont les coefficients de l'√©quation.",
    "La photosynth√®se est un processus par lequel les plantes utilisent la lumi√®re du soleil pour convertir le dioxyde de carbone et l'eau en glucose et oxyg√®ne.",
    "La Seconde Guerre mondiale est un conflit mondial qui a eu lieu de 1939 √† 1945, impliquant la majorit√© des nations du monde, opposant les Alli√©s aux puissances de l'Axe."
]

HEADERS = {
    "Authorization": f"Bearer {GROQ_API_KEY}",
    "Content-Type": "application/json"
}

# Mod√®le d"'embeddings pour mesurer la similarit√© s√©mantique 
embed_model = SentenceTransformer('all-MiniLM-L6-v2')

def ask_model(model_id, question):
    """Interroge l'API Groq avec la question et mod√®le donn√©."""
    payload = {
        "models": model_id,
        "messages": [
            {"role": "system", "content": "Tu es assistant p√©dagogique clair et synth√©tique."},
            {"role": "user", "content": question}
        ],
        "temperature": 0.7
    }
    start = time.time()
    response = requests.post(API_URL, headers=HEADERS, json=payload)
    elapsed = time.time() - start
    if response.status_code == 200:
        content = response.json()["choices"][0]["message"]["content"]
        return content.strip(), elapsed
    else:
        return f"Erreur {response.status_code}", elapsed

def evaluate_similarity(reference, response):
    """Calcule la simularit√© cosine entre r√©f√©rence et r√©ponse."""
    ref_emb = embed_model.encode(reference, convert_to_tensor=True)
    resp_emb = embed_model.encode(response, convert_to_tensor=True)
    similarity = util.pytorch_cos_sim(ref_emb, resp_emb).item()
    return similarity

def length_score(length, ideal=150, tolerance=50):
    """ Score simple pour la longueur : max 1 √† 'ideal', 
        baisse lin√©aire en dehors de [ideal - tol, ideal + tol].
    """
    if length < ideal - tolerance:
        return max(0, length / (ideal - tolerance))
    elif length > ideal + tolerance:
        return max(0, 1 - (length - (ideal + tolerance)) / tolerance)
    else:
        return 1

def main():
    results = []

    print("Lancement des tests sur les mod√®les...\n")
    for i, question in enumerate(QUESTIONS):
        reference = REFERENCES[i]
        for model_name, model_id in MODELS.items():
            answer, duration = ask_model(model_id, question)
            word_count = len(answer.split())
            similarity = evaluate_similarity(reference, answer)
            l_score = length_score(word_count)
            results.append({
                "Question": question,
                "Mod√®le": model_name,
                "Dur√©e (s)": duration,
                "Longueur (mots)": word_count,
                "Score longueur": l_score,
                "Similarit√©": similarity,
                "R√©ponse": answer.replace('\n', '')
            })
            print(f"[{model_name}] Question : '{question[:30]}...' -> Similarit√©: {similarity:.3f}, Dur√©e: {duration:.2f}s, Longueur: {word_count}")
    
    # Affichage d√©taill√© par question
    print("\n=== R√©sultats d√©taill√©s par question ===")
    for i, question in enumerate(QUESTIONS):
        print(f"\nüìö Question {i+1}: {question}")
        print(f"üìñ R√©f√©rence: {REFERENCES[i]}")
        print("-" * 80)
        
        question_results = [r for r in results if r["Question"] == question]
        
        for result in question_results:
            print(f"\nü§ñ Mod√®le: {result['Mod√®le']}")
            print(f"‚ö° Dur√©e: {result['Dur√©e (s)']:.2f}s")
            print(f"üìè Longueur: {result['Longueur (mots)']} mots")
            print(f"üéØ Similarit√©: {result['Similarit√©']:.3f}")
            print(f"üìä Score longueur: {result['Score longueur']:.3f}")
            print(f"üí¨ R√©ponse: {result['R√©ponse'][:200]}...")
        
        # Meilleur mod√®le pour cette question
        best_for_question = max(question_results, key=lambda x: x["Similarit√©"])
        print(f"\nüèÜ Meilleur pour cette question: {best_for_question['Mod√®le']} (Similarit√©: {best_for_question['Similarit√©']:.3f})")
        print("=" * 80)

    # Analyse globale par mod√®le
    summary = {}
    for model_name in MODELS.keys():
        filtered = [r for r in results if r["Mod√®le"] == model_name]
        avg_sim = np.mean([r["Similarit√©"] for r in filtered])
        avg_dur = np.mean([r["Dur√©e (s)"] for r in filtered])
        avg_len = np.mean([r["Score longueur"] for r in filtered])

        # Pond√©ration personnalis√©e - modifie ici si besoin 
        score_global = avg_sim * 0.6 - avg_dur * 0.3 + avg_len * 0.1
        summary[model_name] = {
            "Similarit√© moyenne": avg_sim,
            "Dur√©e moyenne (s)": avg_dur,
            "Score longueur moyen": avg_len,
            "Score global": score_global
        }

    print("\n=== R√©sum√© final ===")
    for model, metrics in summary.items():
        print(f"\nMod√®le: {model}")
        for k, v in metrics.items():
            print(f"  {k}: {v:.3f}")

    meilleur = max(summary.items(), key=lambda x: x[1]["Score global"])
    print(f"\nü•á Meilleur mod√®le selon score global: {meilleur[0]} avec un score de {meilleur[1]['Score global']:.3f}")

if __name__ == "__main__":
    main()